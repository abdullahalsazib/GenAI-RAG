{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e12ac744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import  HumanMessage, SystemMessage, AnyMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"AgenticAIworkspace\"\n",
    "load_dotenv()\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38663e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatGroq(api_key=groq_key, model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a232600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply, divide]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57c3d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Node\n",
    "def assistant(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_message] + state[\"messages\"])]}\n",
    "\n",
    "sys_message = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bf2090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\") # <- back to the brain and make one more decition\n",
    "builder.add_edge(\"assistant\", END)  # Terminate graph\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4adbfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Add 3 and 4. Multiply the output by 2. Divide the output by 5 and what is machin learning (ML) and LLM?' additional_kwargs={} response_metadata={} id='9932901e-965b-479d-b5aa-cf31c4966f02'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': '34wtky43k', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'add'}, 'type': 'function'}, {'id': '97nqd45j8', 'function': {'arguments': '{\"a\":7,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'z2r1x7s3w', 'function': {'arguments': '{\"a\":14,\"b\":5}', 'name': 'divide'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 398, 'total_tokens': 605, 'completion_time': 0.420465436, 'prompt_time': 0.028885059, 'queue_time': 0.063912444, 'total_time': 0.449350495}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--787d5e9f-4fde-42c8-b606-ec79e91c5784-0' tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 4}, 'id': '34wtky43k', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 7, 'b': 2}, 'id': '97nqd45j8', 'type': 'tool_call'}, {'name': 'divide', 'args': {'a': 14, 'b': 5}, 'id': 'z2r1x7s3w', 'type': 'tool_call'}] usage_metadata={'input_tokens': 398, 'output_tokens': 207, 'total_tokens': 605}\n",
      "content='7' name='add' id='681ab6c0-a0c0-47e5-a676-5b4fa2804601' tool_call_id='34wtky43k'\n",
      "content='14' name='multiply' id='987e502e-8167-43a3-87c6-40fcd5d14879' tool_call_id='97nqd45j8'\n",
      "content='2.8' name='divide' id='51be9639-70be-4d8e-83c8-afea1d5266fc' tool_call_id='z2r1x7s3w'\n",
      "content='The output of the operations is 7, then 14, then 2.8.\\n\\nMachine learning (ML) is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models that enable computers to learn from data, identify patterns, and make predictions or decisions without being explicitly programmed.\\n\\nA Large Language Model (LLM) is a type of artificial intelligence designed to process and generate human-like language. It is trained on a massive dataset of text to learn the patterns, structures, and relationships between words, phrases, and sentences. This allows the LLM to generate coherent and contextually relevant text, answer questions, and engage in conversations.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 479, 'total_tokens': 613, 'completion_time': 0.23015079, 'prompt_time': 0.032839501, 'queue_time': 0.049800059, 'total_time': 0.262990291}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--d54884ef-cd06-461a-8574-4b5c78a3eec1-0' usage_metadata={'input_tokens': 479, 'output_tokens': 134, 'total_tokens': 613}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input\n",
    "input_messages = [HumanMessage(content=\"Add 3 and 4. Multiply the output by 2. Divide the output by 5 and what is machin learning (ML) and LLM?\")]\n",
    "\n",
    "# Invoke graph\n",
    "result = graph.invoke({\"messages\": input_messages})\n",
    "\n",
    "# Print messages\n",
    "for msg in result[\"messages\"]:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6d73d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='What is javascript?' additional_kwargs={} response_metadata={} id='348d8f47-2596-4bf7-b051-7d4cea226806'\n",
      "content='<brave_search>' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 369, 'total_tokens': 374, 'completion_time': 0.012374239, 'prompt_time': 0.020443733, 'queue_time': 0.051289442, 'total_time': 0.032817972}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--f184a349-d99e-47c1-8747-5b289f49b369-0' usage_metadata={'input_tokens': 369, 'output_tokens': 5, 'total_tokens': 374}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input\n",
    "input_messages = [HumanMessage(content=\"What is javascript?\")]\n",
    "\n",
    "# Invoke graph\n",
    "result = graph.invoke({\"messages\": input_messages})\n",
    "\n",
    "# Print messages\n",
    "for msg in result[\"messages\"]:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde71cc1",
   "metadata": {},
   "source": [
    " #### Memory Sever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "builder_builder = StateGraph(State)\n",
    "builder_builder.add_node(\"assistant\", assistant)\n",
    "builder_builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder_builder.add_edge(START, \"assistant\")\n",
    "builder_builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder_builder.add_edge(\"tools\", \"assistant\") # <- back to the brain and make one more decition\n",
    "builder_builder.add_edge(\"assistant\", END)  # Terminate graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='add 3 and 4' additional_kwargs={} response_metadata={} id='7354dd30-03ee-4a93-8d03-291cb0ca8b30'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'jz8d2nrd7', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 371, 'total_tokens': 389, 'completion_time': 0.028099938, 'prompt_time': 0.02041292, 'queue_time': 0.05267431, 'total_time': 0.048512858}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--fe3c0ce3-292c-4e6e-aa35-ac01db3b5cfb-0' tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 4}, 'id': 'jz8d2nrd7', 'type': 'tool_call'}] usage_metadata={'input_tokens': 371, 'output_tokens': 18, 'total_tokens': 389}\n",
      "content='7' name='add' id='1ab40591-54f2-40e0-bbd6-0872128b2f8d' tool_call_id='jz8d2nrd7'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': '6gkky3k2q', 'function': {'arguments': '{\"a\":5,\"b\":7}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 400, 'total_tokens': 419, 'completion_time': 0.02037719, 'prompt_time': 0.021947549, 'queue_time': 0.053352581, 'total_time': 0.042324739}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--b41ee741-a774-4667-ba54-2da6e89becf4-0' tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 7}, 'id': '6gkky3k2q', 'type': 'tool_call'}] usage_metadata={'input_tokens': 400, 'output_tokens': 19, 'total_tokens': 419}\n",
      "content='35' name='multiply' id='6221e892-790c-4407-8e6b-0fe2e011e7a4' tool_call_id='6gkky3k2q'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'bw4cb3rq2', 'function': {'arguments': '{\"a\":10,\"b\":2}', 'name': 'divide'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 430, 'total_tokens': 449, 'completion_time': 0.018750602, 'prompt_time': 0.023594307, 'queue_time': 0.048278637, 'total_time': 0.042344909}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ad046780-61ef-46b7-9f62-67ac16c4dad6-0' tool_calls=[{'name': 'divide', 'args': {'a': 10, 'b': 2}, 'id': 'bw4cb3rq2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 430, 'output_tokens': 19, 'total_tokens': 449}\n",
      "content='5.0' name='divide' id='6e9b273c-1200-4d1e-8f3f-c0fef8bdf72f' tool_call_id='bw4cb3rq2'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'd8z93w8ns', 'function': {'arguments': '{\"a\":20,\"b\":0}', 'name': 'divide'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 462, 'total_tokens': 481, 'completion_time': 0.0204801, 'prompt_time': 0.025790034, 'queue_time': 0.052301166, 'total_time': 0.046270134}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--62b62960-ee92-497b-91a2-a3157757356a-0' tool_calls=[{'name': 'divide', 'args': {'a': 20, 'b': 0}, 'id': 'd8z93w8ns', 'type': 'tool_call'}] usage_metadata={'input_tokens': 462, 'output_tokens': 19, 'total_tokens': 481}\n",
      "content=\"Error: ZeroDivisionError('division by zero')\\n Please fix your mistakes.\" name='divide' id='4384f0bc-d5ba-4053-9bae-3079957c520f' tool_call_id='d8z93w8ns' status='error'\n",
      "content='You cannot divide by zero.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 506, 'total_tokens': 513, 'completion_time': 0.008930065, 'prompt_time': 0.02787133, 'queue_time': 0.050909804, 'total_time': 0.036801395}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--d6eb8efc-18a8-4ee6-b409-4f7bf73cd05b-0' usage_metadata={'input_tokens': 506, 'output_tokens': 7, 'total_tokens': 513}\n"
     ]
    }
   ],
   "source": [
    "# specify the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "input_messages = [HumanMessage(content=\"add 3 and 4\")]\n",
    "result = graph.invoke({\"messages\": input_messages}, config=config)\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012951e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ae321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
